{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from math import pi\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyomo.environ import *\n",
    "\n",
    "\n",
    "class RawData:\n",
    "    \"Load raw data to be used in model\"\n",
    "    \n",
    "    def __init__(self, data_dir, scenarios_dir, seed=10):\n",
    "        \n",
    "        # Paths to directories\n",
    "        # --------------------\n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "        \n",
    "        # Network data\n",
    "        # ------------\n",
    "        # Nodes\n",
    "        self.df_n = pd.read_csv(os.path.join(self.data_dir, 'egrimod-nem-dataset-v1.3', 'akxen-egrimod-nem-dataset-4806603', 'network', 'network_nodes.csv'), index_col='NODE_ID')\n",
    "\n",
    "        # AC edges\n",
    "        self.df_e = pd.read_csv(os.path.join(self.data_dir, 'egrimod-nem-dataset-v1.3', 'akxen-egrimod-nem-dataset-4806603', 'network', 'network_edges.csv'), index_col='LINE_ID')\n",
    "\n",
    "        # HVDC links\n",
    "        self.df_hvdc_links = pd.read_csv(os.path.join(self.data_dir, 'egrimod-nem-dataset-v1.3', 'akxen-egrimod-nem-dataset-4806603', 'network', 'network_hvdc_links.csv'), index_col='HVDC_LINK_ID')\n",
    "\n",
    "        # AC interconnector links\n",
    "        self.df_ac_i_links = pd.read_csv(os.path.join(self.data_dir, 'egrimod-nem-dataset-v1.3', 'akxen-egrimod-nem-dataset-4806603', 'network', 'network_ac_interconnector_links.csv'), index_col='INTERCONNECTOR_ID')\n",
    "\n",
    "        # AC interconnector flow limits\n",
    "        self.df_ac_i_limits = pd.read_csv(os.path.join(self.data_dir, 'egrimod-nem-dataset-v1.3', 'akxen-egrimod-nem-dataset-4806603', 'network', 'network_ac_interconnector_flow_limits.csv'), index_col='INTERCONNECTOR_ID')\n",
    "\n",
    "\n",
    "        # Generators\n",
    "        # ----------       \n",
    "        # Generating unit information\n",
    "        self.df_g = pd.read_csv(os.path.join(self.data_dir, 'egrimod-nem-dataset-v1.3', 'akxen-egrimod-nem-dataset-4806603', 'generators', 'generators.csv'), index_col='DUID', dtype={'NODE': int})\n",
    "        \n",
    "        # Perturb short-run marginal costs (SRMCs) so all unique \n",
    "        # (add uniformly distributed random number between 0 and 2 to each SRMC. Set seed so this randomness\n",
    "        # can be reproduced)\n",
    "        np.random.seed(seed)\n",
    "        self.df_g['SRMC_2016-17'] = self.df_g['SRMC_2016-17'] + np.random.uniform(0, 2, self.df_g.shape[0])\n",
    "        \n",
    "        \n",
    "        # Load scenario data\n",
    "        # ------------------\n",
    "        with open(os.path.join(scenarios_dir, 'weekly_scenarios.pickle'), 'rb') as f:\n",
    "            self.df_scenarios = pickle.load(f)\n",
    "        \n",
    "\n",
    "class OrganiseData(RawData):\n",
    "    \"Organise data to be used in mathematical program\"\n",
    "    \n",
    "    def __init__(self, data_dir, scenarios_dir):\n",
    "        # Load model data\n",
    "        super().__init__(data_dir, scenarios_dir)\n",
    "        \n",
    "        \n",
    "    def get_admittance_matrix(self):\n",
    "        \"Construct admittance matrix for network\"\n",
    "\n",
    "        # Initialise dataframe\n",
    "        df_Y = pd.DataFrame(data=0j, index=self.df_n.index, columns=self.df_n.index)\n",
    "\n",
    "        # Off-diagonal elements\n",
    "        for index, row in self.df_e.iterrows():\n",
    "            fn, tn = row['FROM_NODE'], row['TO_NODE']\n",
    "            df_Y.loc[fn, tn] += - (1 / (row['R_PU'] + 1j * row['X_PU'])) * row['NUM_LINES']\n",
    "            df_Y.loc[tn, fn] += - (1 / (row['R_PU'] + 1j * row['X_PU'])) * row['NUM_LINES']\n",
    "\n",
    "        # Diagonal elements\n",
    "        for i in self.df_n.index:\n",
    "            df_Y.loc[i, i] = - df_Y.loc[i, :].sum()\n",
    "\n",
    "        # Add shunt susceptance to diagonal elements\n",
    "        for index, row in self.df_e.iterrows():\n",
    "            fn, tn = row['FROM_NODE'], row['TO_NODE']\n",
    "            df_Y.loc[fn, fn] += (row['B_PU'] / 2) * row['NUM_LINES']\n",
    "            df_Y.loc[tn, tn] += (row['B_PU'] / 2) * row['NUM_LINES']\n",
    "\n",
    "        return df_Y\n",
    "    \n",
    "    \n",
    "    def get_HVDC_incidence_matrix(self):\n",
    "        \"Incidence matrix for HVDC links\"\n",
    "        \n",
    "        # Incidence matrix for HVDC links\n",
    "        df = pd.DataFrame(index=self.df_n.index, columns=self.df_hvdc_links.index, data=0)\n",
    "\n",
    "        for index, row in self.df_hvdc_links.iterrows():\n",
    "            # From nodes assigned a value of 1\n",
    "            df.loc[row['FROM_NODE'], index] = 1\n",
    "\n",
    "            # To nodes assigned a value of -1\n",
    "            df.loc[row['TO_NODE'], index] = -1\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def get_all_ac_edges(self):\n",
    "        \"Tuples defining from and to nodes for all AC edges (forward and reverse)\"\n",
    "        \n",
    "        # Set of all AC edges\n",
    "        edge_set = set()\n",
    "        \n",
    "        # Loop through edges, add forward and reverse direction indice tuples to set\n",
    "        for index, row in self.df_e.iterrows():\n",
    "            edge_set.add((row['FROM_NODE'], row['TO_NODE']))\n",
    "            edge_set.add((row['TO_NODE'], row['FROM_NODE']))\n",
    "        \n",
    "        return edge_set\n",
    "    \n",
    "    \n",
    "    def get_network_graph(self):\n",
    "        \"Graph containing connections between all network nodes\"\n",
    "        network_graph = {n: set() for n in self.df_n.index}\n",
    "\n",
    "        for index, row in self.df_e.iterrows():\n",
    "            network_graph[row['FROM_NODE']].add(row['TO_NODE'])\n",
    "            network_graph[row['TO_NODE']].add(row['FROM_NODE'])\n",
    "        \n",
    "        return network_graph\n",
    "    \n",
    "    \n",
    "    def get_all_dispatchable_fossil_generator_duids(self):\n",
    "        \"Fossil dispatch generator DUIDs\"\n",
    "        \n",
    "        # Filter - keeping only fossil and scheduled generators\n",
    "        mask = (self.df_g['FUEL_CAT'] == 'Fossil') & (self.df_g['SCHEDULE_TYPE'] == 'SCHEDULED')\n",
    "        \n",
    "        return self.df_g[mask].index    \n",
    "       \n",
    "    \n",
    "    def get_reference_nodes(self):\n",
    "        \"Get reference node IDs\"\n",
    "        \n",
    "        # Filter Regional Reference Nodes (RRNs) in Tasmania and Victoria.\n",
    "        mask = (self.df_n['RRN'] == 1) & (self.df_n['NEM_REGION'].isin(['TAS1', 'VIC1']))\n",
    "        reference_node_ids = self.df_n[mask].index\n",
    "        \n",
    "        return reference_node_ids\n",
    "    \n",
    "       \n",
    "    def get_generator_node_map(self, generators):\n",
    "        \"Get set of generators connected to each node\"\n",
    "        \n",
    "        generator_node_map = (self.df_g.reindex(index=generators)\n",
    "                              .reset_index()\n",
    "                              .rename(columns={'OMEGA_G': 'DUID'})\n",
    "                              .groupby('NODE').agg(lambda x: set(x))['DUID']\n",
    "                              .reindex(self.df_n.index, fill_value=set()))\n",
    "        \n",
    "        return generator_node_map\n",
    "    \n",
    "    \n",
    "    def get_ac_interconnector_summary(self):\n",
    "        \"Summarise aggregate flow limit information for AC interconnectors\"\n",
    "\n",
    "        # Create dicitionary containing collections of AC branches for which interconnectors are defined. Create\n",
    "        # These collections for both forward and reverse directions.\n",
    "        interconnector_limits = {}\n",
    "\n",
    "        for index, row in self.df_ac_i_limits.iterrows():\n",
    "            # Forward limit\n",
    "            interconnector_limits[index+'-FORWARD'] = {'FROM_REGION': row['FROM_REGION'], 'TO_REGION': row['TO_REGION'], 'LIMIT': row['FORWARD_LIMIT_MW']}\n",
    "\n",
    "            # Reverse limit\n",
    "            interconnector_limits[index+'-REVERSE'] = {'FROM_REGION': row['TO_REGION'], 'TO_REGION': row['FROM_REGION'], 'LIMIT': row['REVERSE_LIMIT_MW']}\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        df_interconnector_limits = pd.DataFrame(interconnector_limits).T\n",
    "\n",
    "        # Find all branches that consitute each interconnector - order is important. \n",
    "        # First element is 'from' node, second is 'to node\n",
    "        branch_collections = {b: {'branches': list()} for b in df_interconnector_limits.index}\n",
    "\n",
    "        for index, row in self.df_ac_i_links.iterrows():\n",
    "            # For a given branch, find the interconnector index to which it belongs. This will either be the forward or\n",
    "            # reverse direction as defined in the interconnector links DataFrame. If the forward direction, 'FROM_REGION'\n",
    "            # will match between DataFrames, else it indicates the link is in the reverse direction.\n",
    "\n",
    "            # Assign branch to forward interconnector limit ID\n",
    "            mask_forward = (df_interconnector_limits.index.str.contains(index) \n",
    "                      & (df_interconnector_limits['FROM_REGION'] == row['FROM_REGION']) \n",
    "                      & (df_interconnector_limits['TO_REGION'] == row['TO_REGION']))\n",
    "\n",
    "            # Interconnector ID corresponding to branch \n",
    "            branch_index_forward = df_interconnector_limits.loc[mask_forward].index[0]\n",
    "\n",
    "            # Add branch tuple to branch collection\n",
    "            branch_collections[branch_index_forward]['branches'].append((row['FROM_NODE'], row['TO_NODE']))\n",
    "\n",
    "            # Assign branch to reverse interconnector limit ID\n",
    "            mask_reverse = (df_interconnector_limits.index.str.contains(index) \n",
    "                            & (df_interconnector_limits['FROM_REGION'] == row['TO_REGION']) \n",
    "                            & (df_interconnector_limits['TO_REGION'] == row['FROM_REGION']))\n",
    "\n",
    "            # Interconnector ID corresponding to branch \n",
    "            branch_index_reverse = df_interconnector_limits.loc[mask_reverse].index[0]\n",
    "\n",
    "            # Add branch tuple to branch collection\n",
    "            branch_collections[branch_index_reverse]['branches'].append((row['TO_NODE'], row['FROM_NODE']))\n",
    "\n",
    "        # Append branch collections to interconnector limits DataFrame\n",
    "        df_interconnector_limits['branches'] = pd.DataFrame(branch_collections).T['branches']\n",
    "        \n",
    "        return df_interconnector_limits\n",
    "\n",
    "    \n",
    "class DCOPFModel(OrganiseData):\n",
    "    \"Create DCOPF model\"\n",
    "    \n",
    "    def __init__(self, data_dir, scenarios_dir):\n",
    "        # Load model data\n",
    "        super().__init__(data_dir, scenarios_dir)\n",
    "        \n",
    "        # Initialise DCOPF model\n",
    "        self.model = self.create_model()\n",
    "        \n",
    "        \n",
    "        # Setup solver\n",
    "        # ------------\n",
    "        # Import dual variables\n",
    "        self.model.dual = Suffix(direction=Suffix.IMPORT)\n",
    "        \n",
    "        # Specify solver to be used and output format\n",
    "        self.opt = SolverFactory('gurobi', solver_io='mps')\n",
    "        \n",
    "        \n",
    "        # Parameters used for different scenarios\n",
    "        # ---------------------------------------\n",
    "        # Week index\n",
    "        self.week_index = None\n",
    "        \n",
    "        # Scenario index\n",
    "        self.scenario_index = None\n",
    "                \n",
    "        \n",
    "    def create_model(self):\n",
    "        \"Create model object\"\n",
    "        \n",
    "        # Initialise model\n",
    "        model = ConcreteModel()\n",
    "        \n",
    "        \n",
    "        # Sets\n",
    "        # ----   \n",
    "        # Nodes\n",
    "        model.OMEGA_N = Set(initialize=self.df_n.index)\n",
    "\n",
    "        # Generators\n",
    "        model.OMEGA_G = Set(initialize=self.get_all_dispatchable_fossil_generator_duids())\n",
    "\n",
    "        # AC edges\n",
    "        ac_edges = self.get_all_ac_edges()\n",
    "        model.OMEGA_NM = Set(initialize=ac_edges)\n",
    "\n",
    "        # Sets of branches for which aggregate AC interconnector limits are defined\n",
    "        ac_limits = self.get_ac_interconnector_summary()\n",
    "        model.OMEGA_J = Set(initialize=ac_limits.index)\n",
    "\n",
    "        # HVDC links\n",
    "        model.OMEGA_H = Set(initialize=self.df_hvdc_links.index)\n",
    "\n",
    "\n",
    "        # Parameters\n",
    "        # ----------\n",
    "        # System base power\n",
    "        model.BASE_POWER = Param(initialize=100)\n",
    "\n",
    "        # Emissions intensity baseline\n",
    "        model.PHI = Param(initialize=0, mutable=True)\n",
    "\n",
    "        # Permit price\n",
    "        model.TAU = Param(initialize=0, mutable=True)\n",
    "\n",
    "        # Generator emissions intensities\n",
    "        def E_RULE(model, g):\n",
    "            return float(self.df_g.loc[g, 'EMISSIONS'])\n",
    "        model.E = Param(model.OMEGA_G, rule=E_RULE)\n",
    "\n",
    "        # Admittance matrix\n",
    "        admittance_matrix = self.get_admittance_matrix()\n",
    "        def B_RULE(model, n, m):\n",
    "            return float(np.imag(admittance_matrix.loc[n, m]))\n",
    "        model.B = Param(model.OMEGA_NM, rule=B_RULE)\n",
    "\n",
    "        # Reference nodes\n",
    "        reference_nodes = self.get_reference_nodes()\n",
    "        def S_RULE(model, n):\n",
    "            if n in reference_nodes:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        model.S = Param(model.OMEGA_N, rule=S_RULE)\n",
    "\n",
    "        # Generator short-run marginal costs\n",
    "        def C_RULE(model, g):\n",
    "            marginal_cost = float(self.df_g.loc[g, 'SRMC_2016-17'])\n",
    "            return marginal_cost / model.BASE_POWER\n",
    "        model.C = Param(model.OMEGA_G, rule=C_RULE)\n",
    "\n",
    "        # Demand\n",
    "        model.D = Param(model.OMEGA_N, initialize=0, mutable=True)\n",
    "\n",
    "        # Max voltage angle difference between connected nodes\n",
    "        model.THETA_DELTA = Param(initialize=float(pi / 2))\n",
    "\n",
    "        # HVDC incidence matrix\n",
    "        hvdc_incidence_matrix = self.get_HVDC_incidence_matrix()\n",
    "        def K_RULE(model, n, h):\n",
    "            return float(hvdc_incidence_matrix.loc[n, h])\n",
    "        model.K = Param(model.OMEGA_N, model.OMEGA_H, rule=K_RULE)    \n",
    "\n",
    "        # Aggregate AC interconnector flow limits\n",
    "        def F_RULE(model, j):\n",
    "            power_flow_limit = float(ac_limits.loc[j, 'LIMIT'])\n",
    "            return power_flow_limit / model.BASE_POWER\n",
    "        model.F = Param(model.OMEGA_J, rule=F_RULE)\n",
    "\n",
    "        # Power injections from intermittent generators\n",
    "        model.INTERMITTENT = Param(model.OMEGA_N, initialize=0, mutable=True)\n",
    "        \n",
    "        # Power injections from hydro generators\n",
    "        model.HYDRO = Param(model.OMEGA_N, initialize=0, mutable=True)\n",
    "        \n",
    "        # Fixed power injections\n",
    "        def R_RULE(model, n):\n",
    "            return model.INTERMITTENT[n] + model.HYDRO[n]        \n",
    "        model.R = Expression(model.OMEGA_N, rule=R_RULE)\n",
    "        \n",
    "        # Maximum power output\n",
    "        def REGISTERED_CAPACITY_RULE(model, g):\n",
    "            registered_capacity = float(self.df_g.loc[g, 'REG_CAP'])\n",
    "            return registered_capacity / model.BASE_POWER\n",
    "        model.REGISTERED_CAPACITY = Param(model.OMEGA_G, rule=REGISTERED_CAPACITY_RULE)\n",
    "\n",
    "        # Emissions intensity shock indicator parameter. Used to scale original emissions intensities.\n",
    "        model.EMISSIONS_INTENSITY_SHOCK_FACTOR = Param(model.OMEGA_G, initialize=1, mutable=True)\n",
    "        \n",
    "        # Duration of each scenario (will be updated each time model is run. Useful when computing\n",
    "        # total emissions / total scheme revenue etc.)\n",
    "        model.SCENARIO_DURATION = Param(initialize=0, mutable=True)\n",
    "        \n",
    "        \n",
    "        # Variables\n",
    "        # ---------\n",
    "        # Generator output (constrained to non-negative values)\n",
    "        model.p = Var(model.OMEGA_G, within=NonNegativeReals)\n",
    "\n",
    "        # HVDC flows\n",
    "        def P_H_RULE(model, h):\n",
    "            forward_flow_limit = float(self.df_hvdc_links.loc[h, 'FORWARD_LIMIT_MW'])\n",
    "            reverse_flow_limit = float(self.df_hvdc_links.loc[h, 'REVERSE_LIMIT_MW'])\n",
    "            return (- reverse_flow_limit / model.BASE_POWER, forward_flow_limit / model.BASE_POWER)\n",
    "        model.p_H = Var(model.OMEGA_H, bounds=P_H_RULE)\n",
    "\n",
    "        # Node voltage angles\n",
    "        model.theta = Var(model.OMEGA_N)\n",
    "\n",
    "\n",
    "        # Constraints\n",
    "        # -----------\n",
    "        # Power balance\n",
    "        generator_node_map = self.get_generator_node_map(model.OMEGA_G)\n",
    "        network_graph = self.get_network_graph()\n",
    "        def POWER_BALANCE_RULE(model, n):\n",
    "            return (- model.D[n] \n",
    "                    + model.R[n]\n",
    "                    + sum(model.p[g] for g in generator_node_map[n]) \n",
    "                    - sum(model.B[n, m] * (model.theta[n] - model.theta[m]) for m in network_graph[n]) \n",
    "                    - sum(model.K[n, h] * model.p_H[h] for h in model.OMEGA_H) == 0)\n",
    "        model.POWER_BALANCE = Constraint(model.OMEGA_N, rule=POWER_BALANCE_RULE)\n",
    "        \n",
    "        # Max power output\n",
    "        def P_MAX_RULE(model, g):\n",
    "            return model.p[g] <= model.REGISTERED_CAPACITY[g]\n",
    "        model.P_MAX = Constraint(model.OMEGA_G, rule=P_MAX_RULE)\n",
    "\n",
    "        # Reference angle\n",
    "        def REFERENCE_ANGLE_RULE(model, n):\n",
    "            if model.S[n] == 1:\n",
    "                return model.theta[n] == 0\n",
    "            else:\n",
    "                return Constraint.Skip\n",
    "        model.REFERENCE_ANGLE = Constraint(model.OMEGA_N, rule=REFERENCE_ANGLE_RULE)\n",
    "\n",
    "        # Voltage angle difference constraint\n",
    "        def VOLTAGE_ANGLE_DIFFERENCE_RULE(model, n, m):\n",
    "            return model.theta[n] - model.theta[m] - model.THETA_DELTA <= 0\n",
    "        model.VOLTAGE_ANGLE_DIFFERENCE = Constraint(model.OMEGA_NM, rule=VOLTAGE_ANGLE_DIFFERENCE_RULE)\n",
    "\n",
    "        # AC interconnector flow constraints\n",
    "        def AC_FLOW_RULE(model, j):\n",
    "            return sum(model.B[n, m] * (model.theta[n] - model.theta[m]) for n, m in ac_limits.loc[j, 'branches'])\n",
    "        model.AC_FLOW = Expression(model.OMEGA_J, rule=AC_FLOW_RULE)\n",
    "\n",
    "        def AC_POWER_FLOW_LIMIT_RULE(model, j):\n",
    "            return model.AC_FLOW[j] - model.F[j] <= 0\n",
    "        model.AC_POWER_FLOW_LIMIT = Constraint(model.OMEGA_J, rule=AC_POWER_FLOW_LIMIT_RULE)\n",
    "\n",
    "        \n",
    "        # Expressions\n",
    "        # -----------\n",
    "        # Effective emissions intensity (original emissions intensity x scaling factor)\n",
    "        def E_HAT_RULE(model, g):\n",
    "            return model.E[g] * model.EMISSIONS_INTENSITY_SHOCK_FACTOR[g]\n",
    "        model.E_HAT = Expression(model.OMEGA_G, rule=E_HAT_RULE)\n",
    "        \n",
    "        # Total emissions [tCO2]\n",
    "        model.TOTAL_EMISSIONS = Expression(expr=sum(model.p[g] * model.BASE_POWER * model.E_HAT[g] * model.SCENARIO_DURATION for g in model.OMEGA_G))\n",
    "        \n",
    "        # Total energy demand [MWh]\n",
    "        model.TOTAL_ENERGY_DEMAND = Expression(expr=sum(model.D[n] * model.BASE_POWER * model.SCENARIO_DURATION for n in model.OMEGA_N))\n",
    "\n",
    "        # Total energy output from regulated generators [MWh]\n",
    "        model.TOTAL_REGULATED_GENERATOR_ENERGY = Expression(expr=sum(model.p[g] * model.BASE_POWER * model.SCENARIO_DURATION for g in model.OMEGA_G))\n",
    "        \n",
    "        # Total energy from intermittent generators [MWh]\n",
    "        model.TOTAL_INTERMITTENT_ENERGY = Expression(expr=sum(model.INTERMITTENT[n] * model.BASE_POWER * model.SCENARIO_DURATION for n in model.OMEGA_N))\n",
    "        \n",
    "        # Average emissions intensity of regulated generators [tCO2/MWh]\n",
    "        model.AVERAGE_EMISSIONS_INTENSITY_REGULATED_GENERATORS = Expression(expr=model.TOTAL_EMISSIONS / model.TOTAL_REGULATED_GENERATOR_ENERGY)\n",
    "        \n",
    "        # Average emissions intensity of system [tCO2/MWh]\n",
    "        model.AVERAGE_EMISSIONS_INTENSITY_SYSTEM = Expression(expr=model.TOTAL_EMISSIONS / model.TOTAL_ENERGY_DEMAND)\n",
    "        \n",
    "        # Net scheme revenue from regulated 'fossil' generators[$]\n",
    "        model.NET_SCHEME_REVENUE_REGULATED_GENERATORS = Expression(expr=sum((model.E_HAT[g] - model.PHI) * model.p[g] * model.BASE_POWER * model.SCENARIO_DURATION * model.TAU * model.BASE_POWER for g in model.OMEGA_G))\n",
    "        \n",
    "        # Net scheme revenue that would need to be paid to intermittent renewables if included in scheme [$]\n",
    "        model.NET_SCHEME_REVENUE_INTERMITTENT_GENERATORS = Expression(expr= - model.PHI * model.TOTAL_INTERMITTENT_ENERGY * model.TAU * model.BASE_POWER)\n",
    "        \n",
    "\n",
    "        # Objective\n",
    "        # ---------\n",
    "        # Cost minimisation\n",
    "        model.OBJECTIVE = Objective(expr=sum((model.C[g] + ((model.E_HAT[g] - model.PHI) * model.TAU)) * model.p[g] for g in model.OMEGA_G))\n",
    "\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def update_model_parameters(self, week_index, scenario_index, baseline, permit_price):\n",
    "        \"\"\" Update DCOPF model parameters\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : pyomo object\n",
    "            DCOPF OPF model\n",
    "\n",
    "        df_scenarios : pandas DataFrame\n",
    "            Demand and fixed power injection data for each week and each scenario\n",
    "\n",
    "        week_index : int\n",
    "            Index of week for which model should be run\n",
    "\n",
    "        scenario_index : int\n",
    "            Index of scenario that describes operating condition for the given week\n",
    "\n",
    "        baseline: float\n",
    "            Emissions intensity baseline [tCO2/MWh]\n",
    "\n",
    "        permit price : float\n",
    "            Permit price [$/tCO2]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        model : pyomo object\n",
    "            DCOPF model object with updated parameters.    \n",
    "        \"\"\"\n",
    "\n",
    "        # Update fixed nodal power injections\n",
    "        for n in self.model.OMEGA_N:\n",
    "            self.model.D[n] = float(self.df_scenarios.loc[('demand', n), (week_index, scenario_index)] / self.model.BASE_POWER.value)\n",
    "            self.model.HYDRO[n] = float(self.df_scenarios.loc[('hydro', n), (week_index, scenario_index)] / self.model.BASE_POWER.value)\n",
    "            self.model.INTERMITTENT[n] = float(self.df_scenarios.loc[('intermittent', n), (week_index, scenario_index)] / self.model.BASE_POWER.value)\n",
    "            \n",
    "        # Update emissions intensity baseline\n",
    "        self.model.PHI = float(baseline)\n",
    "\n",
    "        # Update permit price\n",
    "        self.model.TAU = float(permit_price / self.model.BASE_POWER.value)\n",
    "        \n",
    "        # Scenario duration\n",
    "        self.model.SCENARIO_DURATION = float(self.df_scenarios.loc[('hours', 'duration'), (week_index, scenario_index)])\n",
    "        \n",
    "        # Update week index\n",
    "        self.week_index = week_index\n",
    "        \n",
    "        # Update scenario index\n",
    "        self.scenario_index = scenario_index\n",
    "               \n",
    "            \n",
    "    def solve_model(self):\n",
    "        \"Solve model\"\n",
    "        \n",
    "        self.opt.solve(self.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "from pyomo.environ import *\n",
    "\n",
    "class MPCModel:\n",
    "    \"Model Predictive Controller used to update emissions intensity baseline\"\n",
    "    \n",
    "    def __init__(self, generator_index, forecast_interval):\n",
    "        # Create model object\n",
    "        self.model = self.mpc_baseline(generator_index, forecast_interval=forecast_interval)       \n",
    "                \n",
    "        # Define solver\n",
    "        self.opt = SolverFactory('gurobi', solver_io='lp')\n",
    "\n",
    "        \n",
    "    def mpc_baseline(self, generator_index, forecast_interval):\n",
    "        \"\"\"Compute baseline path using model predictive control\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        generator_index : list\n",
    "            DUIDs for each generator regulated by the emissions intensity scheme\n",
    "            \n",
    "        forecast_interval : int\n",
    "            Number of periods over which the MPC controller has to achieve its objective\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        model : pyomo model object\n",
    "            Quadratic program used to find path of emissions intensity baseline that\n",
    "            achieves a revenue target while minimising changes to the emissions intensity baseline\n",
    "            over the horizon in which this re-balancing takes place.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialise model object\n",
    "        model = ConcreteModel()\n",
    "\n",
    "\n",
    "        # Sets\n",
    "        # ----\n",
    "        # Generators\n",
    "        model.OMEGA_G = Set(initialize=generator_index)\n",
    "\n",
    "        # Time index\n",
    "        model.OMEGA_T = Set(initialize=range(1, forecast_interval+1), ordered=True)\n",
    "\n",
    "\n",
    "        # Parameters\n",
    "        # ----------\n",
    "        # Predicted generator emissions intensity for future periods\n",
    "        model.EMISSIONS_INTENSITY_FORECAST = Param(model.OMEGA_G, model.OMEGA_T, initialize=0, mutable=True)\n",
    "\n",
    "        # Predicted weekly energy output\n",
    "        model.ENERGY_FORECAST = Param(model.OMEGA_G, model.OMEGA_T, initialize=0, mutable=True)\n",
    "        \n",
    "        # Predicted weekly energy output from intermittent generators\n",
    "        model.INTERMITTENT_ENERGY_FORECAST = Param(model.OMEGA_T, initialize=0, mutable=True)\n",
    "\n",
    "        # Permit price\n",
    "        model.PERMIT_PRICE = Param(initialize=0, mutable=True)\n",
    "\n",
    "        # Emissions intensity baseline from previous period\n",
    "        model.INITIAL_EMISSIONS_INTENSITY_BASELINE = Param(initialize=0, mutable=True)\n",
    "        \n",
    "        # Initial rolling scheme revenue\n",
    "        model.INITIAL_ROLLING_SCHEME_REVENUE = Param(initialize=0, mutable=True)\n",
    "\n",
    "        # Rolling scheme revenue target at end of finite horizon\n",
    "        model.TARGET_ROLLING_SCHEME_REVENUE = Param(initialize=0, mutable=True)\n",
    "        \n",
    "        # Indicator denoting whether energy from intermittent renewables is eligible for scheme payments\n",
    "        model.INTERMITTENT_GENERATORS_REGULATED_INDICATOR = Param(initialize=0, mutable=True)\n",
    "\n",
    "\n",
    "        # Variables\n",
    "        # ---------\n",
    "        # Emissions intensity baseline\n",
    "        model.phi = Var(model.OMEGA_T)\n",
    "\n",
    "\n",
    "        # Constraints\n",
    "        # -----------\n",
    "        # Scheme revenue must be at target by end of model horizon\n",
    "        model.SCHEME_REVENUE = Constraint(expr=model.INITIAL_ROLLING_SCHEME_REVENUE \n",
    "                                          + sum((model.EMISSIONS_INTENSITY_FORECAST[g, t] - model.phi[t]) * model.ENERGY_FORECAST[g, t] * model.PERMIT_PRICE for g in model.OMEGA_G for t in model.OMEGA_T) \n",
    "                                          + sum(model.INTERMITTENT_GENERATORS_REGULATED_INDICATOR[t] * model.INTERMITTENT_ENERGY_FORECAST[t] * model.PERMIT_PRICE for t in model.OMEGA_T)\n",
    "                                          == model.TARGET_ROLLING_SCHEME_REVENUE)\n",
    "\n",
    "        # Baseline must be non-negative\n",
    "        def BASELINE_NONNEGATIVE_RULE(model, t):\n",
    "            return model.phi[t] >= 0\n",
    "        model.BASELINE_NONNEGATIVE = Constraint(model.OMEGA_T, rule=BASELINE_NONNEGATIVE_RULE)\n",
    "\n",
    "\n",
    "        # Objective function\n",
    "        # ------------------\n",
    "        # Minimise changes to baseline over finite time horizon\n",
    "        model.OBJECTIVE = Objective(expr=(((model.phi[model.OMEGA_T.first()] - model.INITIAL_EMISSIONS_INTENSITY_BASELINE) * (model.phi[model.OMEGA_T.first()] - model.INITIAL_EMISSIONS_INTENSITY_BASELINE))\n",
    "                                          + sum((model.phi[t] - model.phi[t-1]) * (model.phi[t] - model.phi[t-1]) for t in model.OMEGA_T if t > model.OMEGA_T.first()))\n",
    "                                   )\n",
    "        return model\n",
    "\n",
    "            \n",
    "    def update_model_parameters(self, forecast_generator_emissions_intensity, forecast_generator_energy, forecast_intermittent_energy, intermittent_generators_regulated, permit_price, initial_emissions_intensity_baseline, initial_rolling_scheme_revenue, target_rolling_scheme_revenue):\n",
    "        \"\"\"Update parameters used as inputs for the MPC controller\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        forecast_generator_emissions_intensity : dict\n",
    "            Expected generator emissions intensities over forecast interval\n",
    "\n",
    "        forecast_generator_energy : dict\n",
    "            Forecast weekly energy output from generators over the forecast interval      \n",
    "            \n",
    "        forecast_intermittent_energy : dict\n",
    "            Forecast weekly intermittent energy output from generators over the forecast interval\n",
    "            \n",
    "        intermittent_generators_regulated : dict\n",
    "            Indicator denoting if energy from renewables receives payments under the scheme\n",
    "\n",
    "        permit_price : float\n",
    "            Emissions price [tCO2/MWh]\n",
    "\n",
    "        initial_emissions_intensity_baseline : float\n",
    "            Emissions intensity baseline implemented for preceding week [tCO2/MWh]\n",
    "\n",
    "        initial_rolling_scheme_revenue : float\n",
    "            Rolling scheme revenue at end of preceding week [$]\n",
    "\n",
    "        target_rolling_scheme_revenue : float\n",
    "            Target scheme revenue to be obtained in the future [$]\n",
    "        \"\"\"\n",
    "\n",
    "        # For each time interval in the forecast horizon\n",
    "        for t in self.model.OMEGA_T:\n",
    "            \n",
    "            if intermittent_generators_regulated[t]:\n",
    "                self.model.INTERMITTENT_GENERATORS_REGULATED_INDICATOR[t] = float(1)\n",
    "            else:\n",
    "                self.model.INTERMITTENT_GENERATORS_REGULATED_INDICATOR[t] = float(0)\n",
    "            \n",
    "            # For each generator\n",
    "            for g in self.model.OMEGA_G:\n",
    "                # Predicted generator emissions intensity for future periods\n",
    "                self.model.EMISSIONS_INTENSITY_FORECAST[g, t] = float(forecast_generator_emissions_intensity[t][g])\n",
    "                \n",
    "                # Predicted weekly energy output\n",
    "                self.model.ENERGY_FORECAST[g, t] = float(forecast_generator_energy[t][g])\n",
    "                \n",
    "                # Predicted weekly energy from intermittent generators\n",
    "                self.model.INTERMITTENT_ENERGY_FORECAST[t] = float(forecast_intermittent_energy[t])\n",
    "\n",
    "        # Permit price\n",
    "        self.model.PERMIT_PRICE = float(permit_price)\n",
    "\n",
    "        # Emissions intensity baseline from previous period\n",
    "        self.model.INITIAL_EMISSIONS_INTENSITY_BASELINE = float(initial_emissions_intensity_baseline)\n",
    "\n",
    "        # Initial rolling scheme revenue\n",
    "        self.model.INITIAL_ROLLING_SCHEME_REVENUE = float(initial_rolling_scheme_revenue)\n",
    "\n",
    "        # Rolling scheme revenue target at end of forecast horizon\n",
    "        self.model.TARGET_ROLLING_SCHEME_REVENUE = float(target_rolling_scheme_revenue)\n",
    "            \n",
    "\n",
    "    def solve_model(self):\n",
    "        \"Solve for optimal emissions intensity baseline path\"\n",
    "\n",
    "        self.opt.solve(self.model)\n",
    "\n",
    "\n",
    "    def get_optimal_baseline_path(self):\n",
    "        \"Get optimal emissions intenstiy baseline path based on MPC controller\"\n",
    "\n",
    "        # Optimal emissions intensity baseline path as determined by MPC controller\n",
    "        optimal_baseline_path = OrderedDict(self.model.phi.get_values())\n",
    "\n",
    "        return optimal_baseline_path\n",
    "\n",
    "\n",
    "    def get_next_baseline(self):\n",
    "        \"Get next baseline to be implemented for the coming week\"\n",
    "\n",
    "        # Optimal path of baselines to be implemented over the finite horizon\n",
    "        optimal_baseline_path = self.get_optimal_baseline_path()\n",
    "\n",
    "        # Next 'optimal' emissions intensity baseline to implement for the coming interval\n",
    "        next_baseline = float(optimal_baseline_path[self.model.OMEGA_T.first()])\n",
    "\n",
    "        return next_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Paths\n",
    "# -----\n",
    "# Directory containing network and generator data\n",
    "data_dir = os.path.join(os.path.curdir, os.path.pardir, os.path.pardir, os.path.pardir, 'data')\n",
    "\n",
    "# Path to scenarios directory\n",
    "scenarios_dir = os.path.join(os.path.curdir, os.path.pardir, os.path.pardir, '1_create_scenarios', 'output')  \n",
    "\n",
    "\n",
    "def run_model(data_dir, scenarios_dir, shock_option, update_mode, description,\n",
    "              intermittent_generators_regulated=dict(),\n",
    "              forecast_generator_emissions_intensity=dict(), \n",
    "              forecast_generator_energy=dict(),\n",
    "              forecast_intermittent_generator_energy=dict(),\n",
    "              forecast_interval_mpc=None,\n",
    "              week_of_shock=None, \n",
    "              default_baseline=0,\n",
    "              initial_permit_price=40, \n",
    "              initial_rolling_scheme_revenue=0, \n",
    "              target_scheme_revenue=dict(), \n",
    "              seed=10, \n",
    "              model_horizon=52):    \n",
    "    \n",
    "    \"\"\"Run model with given parameters\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir : str\n",
    "        Path to directory containing core data files used in model initialisation\n",
    "\n",
    "    scenarios_dir : str\n",
    "        Path to directory containing representative operating scenarios\n",
    "\n",
    "    shock_option : str\n",
    "        Specifies type of shock to which system will be subjected. Options\n",
    "\n",
    "        Options:\n",
    "            NO_SHOCKS                 - No shocks to system\n",
    "            EMISSIONS_INTENSITY_SHOCK - Emissions intensity scaled by a random number between 0.8 \n",
    "                                        and 1 at 'week_of_shock'\n",
    "    update_mode : str\n",
    "        Specifies how baseline should be updated each week. \n",
    "\n",
    "        Options:\n",
    "            NO_UPDATE                -  Same baseline in next iteration\n",
    "            REVENUE_REBALANCE_UPDATE -  Recalibrate baseline by trying to re-balance net scheme \n",
    "                                        revenue every interval\n",
    "            \n",
    "    description : str\n",
    "        Description of model / scenario being tested\n",
    "    \n",
    "    intermittent_generators_regulated : dict\n",
    "        Dictionary containing boolean indicators for each week. If 'True' for a given week, intermittent \n",
    "        generators are subject to the emissions policy and receive payments under the scheme.\n",
    "    \n",
    "    forecast_generator_emissions_intensity : dict\n",
    "        Forecast generator emissions intensities for future periods [tCO2/MWh]\n",
    "        \n",
    "    forecast_generator_energy : dict\n",
    "        Forecast generator energy output for future periods [MWh]\n",
    "        \n",
    "    forecast_intermittent_generator_energy : dict\n",
    "        Forecast intermittent generator output for future periods [MWh]\n",
    "        \n",
    "    forecast_interval_mpc : int or None\n",
    "        Forecast interval for MPC controller. Default = None.\n",
    "    \n",
    "    week_of_shock : int or None\n",
    "        Index for week at which either generation or emissions intensities shocks will be implemented / begin.\n",
    "        Default = 10.\n",
    "\n",
    "    default_baseline : float\n",
    "        Initialised emissions intensity baseline value [tCO2/MWh]. Default = 1 tCO2/MWh.\n",
    "\n",
    "    initial_permit_price : float\n",
    "        Initialised permit price value [$/tCO2]. Default = 40 $/tCO2.\n",
    "        \n",
    "    initial_rolling_scheme_revenue : float\n",
    "        Initialised rolling scheme revenue value [$]. Default = $0.\n",
    "\n",
    "    target_scheme_revenue : dict\n",
    "        Net scheme revenue target defined for each period [$]. Default = $0 for all periods.\n",
    "        \n",
    "    seed : int\n",
    "        Seed used for random number generator. Allows shocks to be reproduced. Default = 10.\n",
    "        \n",
    "    model_horizon : int\n",
    "        Total number of weeks to investigate. Default is 52 weeks (whole year).\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    run_id : str\n",
    "        ID used to identify model run\n",
    "    \"\"\"\n",
    "\n",
    "    # Print model being run\n",
    "    print(f'Running model {update_mode} with run option {shock_option}')\n",
    "\n",
    "    # Summary of all parameters defining the model\n",
    "    parameter_values = (shock_option, update_mode, description, intermittent_generators_regulated,\n",
    "                        forecast_generator_emissions_intensity, forecast_generator_energy, \n",
    "                        forecast_interval_mpc, week_of_shock, default_baseline, initial_permit_price, \n",
    "                        initial_rolling_scheme_revenue, target_scheme_revenue, seed, model_horizon)\n",
    "    \n",
    "    # Convert parameters to string\n",
    "    parameter_values_string = ''.join([str(i) for i in parameter_values])\n",
    "\n",
    "    # Find sha256 of parameter values - used as a unique identifier for the model run\n",
    "    run_id = hashlib.sha256(parameter_values_string.encode('utf-8')).hexdigest()[:8].upper()\n",
    "\n",
    "    # Summary of model options, identified by the hash value of these options\n",
    "    run_summary = {run_id: {'shock_option': shock_option, \n",
    "                            'update_mode': update_mode,\n",
    "                            'description': description,\n",
    "                            'intermittent_generators_regulated': intermittent_generators_regulated,\n",
    "                            'forecast_generator_emissions_intensity': forecast_generator_emissions_intensity,\n",
    "                            'forecast_generator_energy': forecast_generator_energy,\n",
    "                            'forecast_intermittent_generator_energy': forecast_intermittent_generator_energy,\n",
    "                            'forecast_interval_mpc': forecast_interval_mpc,\n",
    "                            'week_of_shock': week_of_shock,\n",
    "                            'default_baseline': default_baseline, \n",
    "                            'initial_permit_price': initial_permit_price,\n",
    "                            'initial_rolling_scheme_revenue': initial_rolling_scheme_revenue, \n",
    "                            'target_scheme_revenue': target_scheme_revenue,                            \n",
    "                            'seed': seed,\n",
    "                            'model_horizon': model_horizon}\n",
    "                  }\n",
    "\n",
    "\n",
    "    # Check if model parameters valid\n",
    "    # -------------------------------\n",
    "    if update_mode not in ['NO_UPDATE', 'REVENUE_REBALANCE_UPDATE', 'MPC_UPDATE']:\n",
    "        raise Warning(f'Unexpected update_mode encountered: {update_mode}')\n",
    "\n",
    "    if shock_option not in ['NO_SHOCKS', 'EMISSIONS_INTENSITY_SHOCK']:\n",
    "        raise Warning(f'Unexpected shock_option encountered: {shock_option}')\n",
    "\n",
    "\n",
    "    # Create model objects\n",
    "    # --------------------\n",
    "    # Instantiate DCOPF model object\n",
    "    DCOPF = DCOPFModel(data_dir=data_dir, scenarios_dir=scenarios_dir)\n",
    "\n",
    "    # Instantiate Model Predictive Controller if MPC update specified\n",
    "    if update_mode == 'MPC_UPDATE':\n",
    "        MPC = MPCModel(generator_index=DCOPF.model.OMEGA_G, forecast_interval=forecast_interval_mpc)\n",
    "    \n",
    "    \n",
    "    # Result containers\n",
    "    # -----------------\n",
    "    # Prices at each node for each scenario\n",
    "    scenario_nodal_prices = dict()\n",
    "    \n",
    "    # Power output for each scenario\n",
    "    scenario_power_output = dict()\n",
    "\n",
    "    # Results for each scenario\n",
    "    scenario_metrics = {'net_scheme_revenue_regulated_generators': dict(),\n",
    "                        'net_scheme_revenue_intermittent_generators': dict(),\n",
    "                        'total_emissions_tCO2': dict(),\n",
    "                        'regulated_generator_energy_MWh': dict(),\n",
    "                        'total_regulated_generator_energy_MWh': dict(),\n",
    "                        'total_intermittent_energy_MWh': dict(),\n",
    "                        'total_demand_MWh': dict(),\n",
    "                        'energy_revenue': dict(),\n",
    "                       }\n",
    "    \n",
    "    # Aggregated results for each week\n",
    "    week_metrics = {'baseline': dict(),\n",
    "                    'net_scheme_revenue_regulated_generators': dict(),\n",
    "                    'net_scheme_revenue_intermittent_generators': dict(),\n",
    "                    'net_scheme_revenue': dict(),\n",
    "                    'rolling_scheme_revenue_interval_start': dict(),\n",
    "                    'rolling_scheme_revenue_interval_end': dict(),\n",
    "                    'regulated_generator_emissions_intensities': dict(),\n",
    "                    'total_emissions_tCO2': dict(),\n",
    "                    'regulated_generator_energy_MWh': dict(),\n",
    "                    'total_regulated_generator_energy_MWh': dict(),\n",
    "                    'total_intermittent_energy_MWh': dict(),\n",
    "                    'total_demand_MWh': dict(),\n",
    "                    'average_emissions_intensity_regulated_generators': dict(),\n",
    "                    'average_emissions_intensity_system': dict(),\n",
    "                    'energy_revenue': dict(),\n",
    "                    'average_energy_price': dict(),\n",
    "                   }\n",
    "    \n",
    "    # Random shocks \n",
    "    # -------------\n",
    "    # Set seed so random shocks can be reproduced if needed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Augment original emissions intensity by random scaling factor between 0.8 and 1\n",
    "    if shock_option == 'EMISSIONS_INTENSITY_SHOCK':\n",
    "        df_emissions_intensity_shock_factor = pd.Series(index=DCOPF.model.OMEGA_G, data=np.random.uniform(0.8, 1, len(DCOPF.model.OMEGA_G)))\n",
    "\n",
    "\n",
    "    # Run scenarios\n",
    "    # -------------\n",
    "    # Week indices for which model will be run (can run for less than one year by using model_horizon)\n",
    "    weeks = DCOPF.df_scenarios.columns.levels[0][:model_horizon]\n",
    "    \n",
    "    # For each week\n",
    "    for week_index in weeks:\n",
    "        # Start clock to see how long it takes to solve all scenarios for each week\n",
    "        t0 = time.time()\n",
    "        \n",
    "        # Initialise policy parameters if the first week\n",
    "        if week_index == 1:            \n",
    "            # Initialise permit price\n",
    "            permit_price = initial_permit_price\n",
    "            \n",
    "            # Initialise rolling scheme revenue (value at the end of previous calibration interval)\n",
    "            rolling_scheme_revenue_interval_start = initial_rolling_scheme_revenue\n",
    "        \n",
    "        \n",
    "        # Update rolling scheme revenue (amount of money in bank account at start of calibration interval)\n",
    "        if week_index > 1:\n",
    "            rolling_scheme_revenue_interval_start = week_metrics['rolling_scheme_revenue_interval_end'][week_index-1]\n",
    "\n",
    "        # Record amount of money in bank account at start of calibration interval\n",
    "        week_metrics['rolling_scheme_revenue_interval_start'][week_index] = rolling_scheme_revenue_interval_start\n",
    "        \n",
    "            \n",
    "        # Compute baseline\n",
    "        # ----------------\n",
    "        if update_mode == 'NO_UPDATE':\n",
    "            # No update to baseline (should be 0 tCO2/MWh)\n",
    "            baseline = default_baseline\n",
    "\n",
    "        elif update_mode == 'REVENUE_REBALANCE_UPDATE':\n",
    "            # Forecast regulated generator emissions in next period\n",
    "            forecast_regulated_generator_total_emissions = sum(forecast_generator_emissions_intensity[week_index][1][g] * forecast_generator_energy[week_index][1][g] for g in DCOPF.model.OMEGA_G)\n",
    "\n",
    "            # Forecast energy output from 'fossil' generators (definitely under policy's remit)\n",
    "            forecast_fossil_generator_total_energy = sum(forecast_generator_energy[week_index][1][g] for g in DCOPF.model.OMEGA_G)\n",
    "            \n",
    "            # Forecast energy from intermittent reneweable generators (may be under scheme's remit)\n",
    "            forecast_intermittent_generator_total_energy = forecast_intermittent_generator_energy[week_index][1]\n",
    "            \n",
    "            # Forecast regulated generator energy in next period. Value may change depending on whether or not\n",
    "            # intermittent generators are subject to the scheme's remit.\n",
    "            if intermittent_generators_regulated and intermittent_generators_regulated[week_index]:\n",
    "                # Intermittent generators are part of scheme's remit, and receive payments\n",
    "                forecast_regulated_generator_total_energy = forecast_fossil_generator_total_energy + forecast_intermittent_generator_total_energy\n",
    "            else:\n",
    "                # Only output from fossil generators considered\n",
    "                forecast_regulated_generator_total_energy = forecast_fossil_generator_total_energy\n",
    "                \n",
    "            # Forecast regulated generator average emissions intensity\n",
    "            forecast_regulated_generator_average_emissions_intensity = forecast_regulated_generator_total_emissions / forecast_regulated_generator_total_energy\n",
    "\n",
    "            # Update baseline seeking to re-balance net scheme revenue every period based on forecast output\n",
    "            baseline = forecast_regulated_generator_average_emissions_intensity - ((target_scheme_revenue[week_index] - rolling_scheme_revenue_interval_start) / (permit_price * forecast_regulated_generator_total_energy))\n",
    "\n",
    "            # Set baseline to 0 if updated value less than zero\n",
    "            if baseline < 0:\n",
    "                baseline = 0\n",
    "        \n",
    "        elif update_mode == 'MPC_UPDATE':\n",
    "            # Update baseline using a Model Predictive Control paradigm. Goal is to minimise control \n",
    "            # action (movement of baseline) while achieving target scheme revenue 6 weeks in the future.\n",
    "            \n",
    "            # If first week, set previous baseline to expected emissions intensity for coming week\n",
    "            if week_index == 1:\n",
    "                baseline = 1.02\n",
    "                \n",
    "            # Have limited information at end of model horizon to make forecast e.g. in the 2nd to last\n",
    "            # week it's not possible to forecast 6 weeks in the future. Instead use the forecast from the\n",
    "            # last optimal path calculated.\n",
    "            if week_index <= weeks[-1] - forecast_interval_mpc + 1:\n",
    "                # Expected generator energy output in forecast interval\n",
    "                forecast_energy = forecast_generator_energy[week_index]\n",
    "                \n",
    "                # Expected generator emissions intensities in forecast interval\n",
    "                forecast_emissions_intensity = forecast_generator_emissions_intensity[week_index]\n",
    "                \n",
    "                # Expected energy output from renewables over forecast interval\n",
    "                forecast_intermittent_energy = forecast_intermittent_generator_energy[week_index]\n",
    "                \n",
    "                                            \n",
    "                # Update MPC controller parameters\n",
    "                MPC.update_model_parameters(forecast_generator_emissions_intensity=forecast_emissions_intensity,\n",
    "                                            forecast_generator_energy=forecast_energy,\n",
    "                                            forecast_intermittent_generator_energy=forecast_intermittent_energy,\n",
    "                                            permit_price=permit_price,\n",
    "                                            initial_emissions_intensity_baseline=baseline,\n",
    "                                            initial_rolling_scheme_revenue=rolling_scheme_revenue_interval_start,\n",
    "                                            target_rolling_scheme_revenue=target_scheme_revenue[week_index])\n",
    "                                \n",
    "                # Solve model\n",
    "                MPC.solve_model()\n",
    "            \n",
    "                # Get next baseline to be implemented\n",
    "                baseline_path = MPC.get_optimal_baseline_path()\n",
    "            \n",
    "                # Baseline to be implemented next\n",
    "                baseline = list(baseline_path.items())[0][1]\n",
    "            \n",
    "            else:\n",
    "                # Find index of baseline from optimal path previously calculated\n",
    "                baseline_path_index = week_index - (weeks[-1] - forecast_interval_mpc)\n",
    "                \n",
    "                # Baseline to be implemented\n",
    "                baseline = list(baseline_path.items())[baseline_path_index-1][1]\n",
    "                \n",
    "        # Record baseline applying for the given week\n",
    "        week_metrics['baseline'][week_index] = baseline\n",
    "        \n",
    "        # Apply emissions intensity shock if shock option specified. Shock occurs once at week_index \n",
    "        # given by week_of_shock\n",
    "        if (shock_option == 'EMISSIONS_INTENSITY_SHOCK') and (week_index == week_of_shock):\n",
    "            # Loop through generators\n",
    "            for g in DCOPF.model.OMEGA_G:\n",
    "                # Augment generator emissions intensity factor\n",
    "                DCOPF.model.EMISSIONS_INTENSITY_SHOCK_FACTOR[g] = float(df_emissions_intensity_shock_factor.loc[g])\n",
    "\n",
    "        # For each representative scenario approximating a week's operating state\n",
    "        for scenario_index in DCOPF.df_scenarios.columns.levels[1]:        \n",
    "            # Update model parameters\n",
    "            DCOPF.update_model_parameters(week_index=week_index,\n",
    "                                          scenario_index=scenario_index, \n",
    "                                          baseline=baseline, \n",
    "                                          permit_price=permit_price)\n",
    "\n",
    "            # Solve model\n",
    "            DCOPF.solve_model()\n",
    "\n",
    "\n",
    "            # Store results\n",
    "            # -------------\n",
    "            # Nodal prices\n",
    "            scenario_nodal_prices[(week_index, scenario_index)] = {n: DCOPF.model.dual[DCOPF.model.POWER_BALANCE[n]] for n in DCOPF.model.OMEGA_N}\n",
    "\n",
    "            # Power output from each generator\n",
    "            scenario_power_output[(week_index, scenario_index)] = DCOPF.model.p.get_values()\n",
    "            \n",
    "            \n",
    "            # Store scenario metrics\n",
    "            # ----------------------\n",
    "            # Net scheme revenue from regulated 'fossil' generators for each scenario [$]\n",
    "            scenario_metrics['net_scheme_revenue_regulated_generators'][(week_index, scenario_index)] = DCOPF.model.NET_SCHEME_REVENUE_REGULATED_GENERATORS.expr()\n",
    "            \n",
    "            # Net scheme revenue that would need to be paid to intermittent renewables if included in scheme [$]\n",
    "            scenario_metrics['net_scheme_revenue_intermittent_generators'][(week_index, scenario_index)] = DCOPF.model.NET_SCHEME_REVENUE_INTERMITTENT_GENERATORS.expr()\n",
    "            \n",
    "            # Total emissions [tCO2]\n",
    "            scenario_metrics['total_emissions_tCO2'][(week_index, scenario_index)] = DCOPF.model.TOTAL_EMISSIONS.expr()\n",
    "            \n",
    "            # Generator energy output\n",
    "            scenario_metrics['regulated_generator_energy_MWh'][(week_index, scenario_index)] = {g: DCOPF.model.p[g].value * DCOPF.model.BASE_POWER.value * DCOPF.model.SCENARIO_DURATION.value for g in DCOPF.model.OMEGA_G}\n",
    "            \n",
    "            # Total emissions from regulated generators [tCO2]\n",
    "            scenario_metrics['total_regulated_generator_energy_MWh'][(week_index, scenario_index)] = DCOPF.model.TOTAL_REGULATED_GENERATOR_ENERGY.expr()\n",
    "            \n",
    "            # Total energy from intermittent generators [MWh]\n",
    "            scenario_metrics['total_intermittent_energy_MWh'][(week_index, scenario_index)] = DCOPF.model.TOTAL_INTERMITTENT_ENERGY.expr()\n",
    "            \n",
    "            # Total system energy demand [MWh]\n",
    "            scenario_metrics['total_demand_MWh'][(week_index, scenario_index)] = DCOPF.model.TOTAL_ENERGY_DEMAND.expr()\n",
    "            \n",
    "            # Total revenue from energy sales (nodal price x nodal demand x scenario duration)\n",
    "            scenario_metrics['energy_revenue'][(week_index, scenario_index)] = sum(DCOPF.model.dual[DCOPF.model.POWER_BALANCE[n]] * DCOPF.model.BASE_POWER.value * DCOPF.model.D[n].value * DCOPF.model.BASE_POWER.value * DCOPF.model.SCENARIO_DURATION.value for n in DCOPF.model.OMEGA_N)\n",
    "            \n",
    "\n",
    "            \n",
    "        # Compute aggregate statistics for given week\n",
    "        # -------------------------------------------\n",
    "        # Net scheme revenue from regulated 'fossil' generators for each week [$]\n",
    "        week_metrics['net_scheme_revenue_regulated_generators'][week_index] = sum(scenario_metrics['net_scheme_revenue_regulated_generators'][(week_index, s)] for s in DCOPF.df_scenarios.columns.levels[1])\n",
    "        \n",
    "        # Net scheme revenue that would need to be paid to intermittent renewables each week if included in scheme [$]\n",
    "        week_metrics['net_scheme_revenue_intermittent_generators'][week_index] = sum(scenario_metrics['net_scheme_revenue_intermittent_generators'][(week_index, s)] for s in DCOPF.df_scenarios.columns.levels[1])\n",
    "        \n",
    "        # Net scheme revenue depending on inclusion of intermittent renewables in schemes [$]\n",
    "        if intermittent_generators_regulated and intermittent_generators_regulated[week_index]:\n",
    "            week_metrics['net_scheme_revenue'][week_index] = week_metrics['net_scheme_revenue_regulated_generators'][week_index] + week_metrics['net_scheme_revenue_intermittent_generators'][week_index]\n",
    "        else:\n",
    "            week_metrics['net_scheme_revenue'][week_index] = week_metrics['net_scheme_revenue_regulated_generators'][week_index]\n",
    "        \n",
    "        # Emissions intensities for regulated generators for the given week\n",
    "        week_metrics['regulated_generator_emissions_intensities'][week_index] = {g: DCOPF.model.E_HAT[g].expr() for g in DCOPF.model.OMEGA_G}\n",
    "\n",
    "        # Total emissions [tCO2]\n",
    "        week_metrics['total_emissions_tCO2'][week_index] = sum(scenario_metrics['total_emissions_tCO2'][(week_index, s)] for s in DCOPF.df_scenarios.columns.levels[1])\n",
    "        \n",
    "        # Weekly energy output for each generator\n",
    "        week_metrics['regulated_generator_energy_MWh'][week_index] = {g: sum(scenario_metrics['regulated_generator_energy_MWh'][(week_index, s)][g] for s in DCOPF.df_scenarios.columns.levels[1]) for g in DCOPF.model.OMEGA_G}\n",
    "        \n",
    "        # Total output from generators subjected to emissions intensity policy [MWh]\n",
    "        week_metrics['total_regulated_generator_energy_MWh'][week_index] = sum(scenario_metrics['total_regulated_generator_energy_MWh'][(week_index, s)] for s in DCOPF.df_scenarios.columns.levels[1])\n",
    "        \n",
    "        # Total energy from intermittent generators [MWh] (these incumbent generators are generally not subjected to policy)\n",
    "        week_metrics['total_intermittent_energy_MWh'][week_index] = sum(scenario_metrics['total_intermittent_energy_MWh'][(week_index, s)] for s in DCOPF.df_scenarios.columns.levels[1])\n",
    "        \n",
    "        # Total energy demand in given week [MWh]\n",
    "        week_metrics['total_demand_MWh'][week_index] = sum(scenario_metrics['total_demand_MWh'][(week_index, s)] for s in DCOPF.df_scenarios.columns.levels[1])\n",
    "        \n",
    "        # Average emissions intensity of regulated generators [tCO2/MWh]\n",
    "        week_metrics['average_emissions_intensity_regulated_generators'][week_index] = week_metrics['total_emissions_tCO2'][week_index] / week_metrics['total_regulated_generator_energy_MWh'][week_index]\n",
    "        \n",
    "        # Average emissions intensity of whole system (including renewables) [tCO2/MWh]\n",
    "        week_metrics['average_emissions_intensity_system'][week_index] = week_metrics['total_emissions_tCO2'][week_index] / week_metrics['total_demand_MWh'][week_index]            \n",
    "                   \n",
    "        # Record rolling scheme revenue at end of calibration interval [$]\n",
    "        week_metrics['rolling_scheme_revenue_interval_end'][week_index] = rolling_scheme_revenue_interval_start + week_metrics['net_scheme_revenue'][week_index]\n",
    "        \n",
    "        # Total revenue from energy sales for given week [$]\n",
    "        week_metrics['energy_revenue'][week_index] = sum(scenario_metrics['energy_revenue'][(week_index, s)] for s in DCOPF.df_scenarios.columns.levels[1])\n",
    "\n",
    "        # Average energy price [$/MWh]\n",
    "        week_metrics['average_energy_price'][week_index] = week_metrics['energy_revenue'][week_index] / week_metrics['total_demand_MWh'][week_index]\n",
    "        \n",
    "        \n",
    "        print(f'Completed week {week_index} in {time.time()-t0:.2f}s')\n",
    "\n",
    "        \n",
    "    # Save results\n",
    "    # ------------\n",
    "    with open(f'output/{run_id}_scenario_nodal_prices.pickle', 'wb') as f:\n",
    "        pickle.dump(scenario_nodal_prices, f)\n",
    "\n",
    "    with open(f'output/{run_id}_scenario_power_output.pickle', 'wb') as f:\n",
    "        pickle.dump(scenario_power_output, f)\n",
    "\n",
    "    with open(f'output/{run_id}_scenario_metrics.pickle', 'wb') as f:\n",
    "        pickle.dump(scenario_metrics, f)\n",
    "        \n",
    "    with open(f'output/{run_id}_week_metrics.pickle', 'wb') as f:\n",
    "        pickle.dump(week_metrics, f)\n",
    "        \n",
    "    with open(f'output/{run_id}_run_summary.pickle', 'wb') as f:\n",
    "        pickle.dump(run_summary, f)\n",
    "\n",
    "    with open(f'output/{run_id}_generators.pickle', 'wb') as f:\n",
    "        pickle.dump(DCOPF.df_g, f)\n",
    "        \n",
    "    if shock_option == 'EMISSIONS_INTENSITY_SHOCK':\n",
    "        with open(f'output/{run_id}_emissions_intensity_shock_factor.pickle', 'wb') as f:\n",
    "            pickle.dump(df_emissions_intensity_shock_factor, f)\n",
    "        \n",
    "    return run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run model with different scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model NO_UPDATE with run option NO_SHOCKS\n",
      "Completed week 1 in 11.72s\n",
      "Completed week 2 in 11.64s\n",
      "Completed week 3 in 11.59s\n",
      "Completed week 4 in 11.94s\n",
      "Completed week 5 in 11.98s\n",
      "Completed week 6 in 11.64s\n",
      "Completed week 7 in 11.62s\n",
      "Completed week 8 in 11.58s\n",
      "Completed week 9 in 11.60s\n",
      "Completed week 10 in 11.91s\n",
      "Running model NO_UPDATE with run option NO_SHOCKS\n",
      "Completed week 1 in 11.86s\n",
      "Completed week 2 in 12.17s\n",
      "Completed week 3 in 11.81s\n",
      "Completed week 4 in 11.55s\n",
      "Completed week 5 in 11.78s\n",
      "Completed week 6 in 11.61s\n",
      "Completed week 7 in 11.55s\n",
      "Completed week 8 in 11.64s\n",
      "Completed week 9 in 11.52s\n",
      "Completed week 10 in 11.72s\n",
      "Running model NO_UPDATE with run option EMISSIONS_INTENSITY_SHOCK\n",
      "Completed week 1 in 11.71s\n",
      "Completed week 2 in 11.54s\n",
      "Completed week 3 in 11.64s\n",
      "Completed week 4 in 11.52s\n",
      "Completed week 5 in 11.83s\n",
      "Completed week 6 in 11.72s\n",
      "Completed week 7 in 11.63s\n",
      "Completed week 8 in 11.66s\n",
      "Completed week 9 in 11.70s\n",
      "Completed week 10 in 11.58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'F8814267'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "# ----------\n",
    "model_horizon = 10\n",
    "week_of_shock = 3\n",
    "\n",
    "# Business-as-usual case\n",
    "run_model(data_dir=data_dir,\n",
    "          scenarios_dir=scenarios_dir,\n",
    "          shock_option='NO_SHOCKS',\n",
    "          update_mode='NO_UPDATE',\n",
    "          description='business as usual case',\n",
    "          forecast_generator_emissions_intensity=dict(),\n",
    "          forecast_generator_energy=dict(),\n",
    "          forecast_interval_mpc=None,\n",
    "          week_of_shock=None,\n",
    "          default_baseline=0,\n",
    "          initial_permit_price=0,\n",
    "          initial_rolling_scheme_revenue=0,\n",
    "          target_scheme_revenue=dict(),\n",
    "          seed=10,\n",
    "          model_horizon=model_horizon)\n",
    "\n",
    "# Carbon tax - no shocks\n",
    "run_model(data_dir=data_dir,\n",
    "          scenarios_dir=scenarios_dir,\n",
    "          shock_option='NO_SHOCKS',\n",
    "          update_mode='NO_UPDATE',\n",
    "          description='carbon tax - no shocks',\n",
    "          forecast_generator_emissions_intensity=dict(),\n",
    "          forecast_generator_energy=dict(),\n",
    "          forecast_interval_mpc=None,\n",
    "          week_of_shock=None,\n",
    "          default_baseline=0,\n",
    "          initial_permit_price=40,\n",
    "          initial_rolling_scheme_revenue=0,\n",
    "          target_scheme_revenue=dict(),\n",
    "          seed=10,\n",
    "          model_horizon=model_horizon)\n",
    "\n",
    "# Carbon tax - emissions intensity shock\n",
    "run_model(data_dir=data_dir,\n",
    "          scenarios_dir=scenarios_dir,\n",
    "          shock_option='EMISSIONS_INTENSITY_SHOCK',\n",
    "          update_mode='NO_UPDATE',\n",
    "          description='carbon tax - emissions intensity shock',\n",
    "          forecast_generator_emissions_intensity=dict(),\n",
    "          forecast_generator_energy=dict(),\n",
    "          forecast_interval_mpc=None,\n",
    "          week_of_shock=week_of_shock,\n",
    "          default_baseline=0,\n",
    "          initial_permit_price=40,\n",
    "          initial_rolling_scheme_revenue=0,\n",
    "          target_scheme_revenue=dict(),\n",
    "          seed=10,\n",
    "          model_horizon=model_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'forecast_interval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-00c17dc76047>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_horizon\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforecast_interval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_horizon\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-00c17dc76047>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_horizon\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforecast_interval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_horizon\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'forecast_interval' is not defined"
     ]
    }
   ],
   "source": [
    "# intermittent_generators_regulated\n",
    "a = {i: False for i in range(1, model_horizon+1)}\n",
    "\n",
    "{i: {j+1: a[i+j] for j in range(0, forecast_interval)} for i in range(1, model_horizon+1)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shock_option</th>\n",
       "      <th>update_mode</th>\n",
       "      <th>description</th>\n",
       "      <th>forecast_generator_emissions_intensity</th>\n",
       "      <th>forecast_generator_energy</th>\n",
       "      <th>forecast_interval_mpc</th>\n",
       "      <th>week_of_shock</th>\n",
       "      <th>default_baseline</th>\n",
       "      <th>initial_permit_price</th>\n",
       "      <th>initial_rolling_scheme_revenue</th>\n",
       "      <th>target_scheme_revenue</th>\n",
       "      <th>seed</th>\n",
       "      <th>model_horizon</th>\n",
       "      <th>intermittent_generators_regulated</th>\n",
       "      <th>forecast_intermittent_generator_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1AE01292</th>\n",
       "      <td>EMISSIONS_INTENSITY_SHOCK</td>\n",
       "      <td>NO_UPDATE</td>\n",
       "      <td>carbon tax - emissions intensity shock</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25509009</th>\n",
       "      <td>NO_SHOCKS</td>\n",
       "      <td>REVENUE_REBALANCE_UPDATE</td>\n",
       "      <td>Attempt to re-balance revenue in each period</td>\n",
       "      <td>{1: {1: {'DRYCGT1': 1.35599, 'BW01': 0.9674, '...</td>\n",
       "      <td>{1: {1: {'DRYCGT1': 0.0, 'BW01': 110880.0, 'MP...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>{1: 100000.0, 2: 200000.0, 3: 300000.0, 4: 400...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5B6BDE7D</th>\n",
       "      <td>EMISSIONS_INTENSITY_SHOCK</td>\n",
       "      <td>MPC_UPDATE</td>\n",
       "      <td>Use MPC to achieve revenue target at end of ho...</td>\n",
       "      <td>{1: {1: {'DRYCGT1': 1.35599, 'BW01': 0.9674, '...</td>\n",
       "      <td>{1: {1: {'DRYCGT1': 0.0, 'BW01': 110880.0, 'MP...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>{1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: ...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6929315F</th>\n",
       "      <td>EMISSIONS_INTENSITY_SHOCK</td>\n",
       "      <td>REVENUE_REBALANCE_UPDATE</td>\n",
       "      <td>Attempt to re-balance revenue in each period</td>\n",
       "      <td>{1: {1: {'DRYCGT1': 1.35599, 'BW01': 0.9674, '...</td>\n",
       "      <td>{1: {1: {'DRYCGT1': 0.0, 'BW01': 110880.0, 'MP...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>{1: 0, 2: 0, 3: 0, 4: 0, 5: 2500000.0, 6: 3000...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780A1969</th>\n",
       "      <td>NO_SHOCKS</td>\n",
       "      <td>MPC_UPDATE</td>\n",
       "      <td>Use MPC to achieve revenue target at end of ho...</td>\n",
       "      <td>{1: {1: {'DRYCGT1': 1.35599, 'BW01': 0.9674, '...</td>\n",
       "      <td>{1: {1: {'DRYCGT1': 0.0, 'BW01': 110880.0, 'MP...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>{1: 0, 2: 0, 3: 0, 4: 0, 5: 1000000.0}</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78262511</th>\n",
       "      <td>NO_SHOCKS</td>\n",
       "      <td>NO_UPDATE</td>\n",
       "      <td>business as usual case</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7958E7BA</th>\n",
       "      <td>NO_SHOCKS</td>\n",
       "      <td>NO_UPDATE</td>\n",
       "      <td>carbon tax - no shocks</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993808E9</th>\n",
       "      <td>NO_SHOCKS</td>\n",
       "      <td>NO_UPDATE</td>\n",
       "      <td>business as usual case</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D368B8D5</th>\n",
       "      <td>NO_SHOCKS</td>\n",
       "      <td>NO_UPDATE</td>\n",
       "      <td>carbon tax - no shocks</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F8814267</th>\n",
       "      <td>EMISSIONS_INTENSITY_SHOCK</td>\n",
       "      <td>NO_UPDATE</td>\n",
       "      <td>carbon tax - emissions intensity shock</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       shock_option               update_mode  \\\n",
       "1AE01292  EMISSIONS_INTENSITY_SHOCK                 NO_UPDATE   \n",
       "25509009                  NO_SHOCKS  REVENUE_REBALANCE_UPDATE   \n",
       "5B6BDE7D  EMISSIONS_INTENSITY_SHOCK                MPC_UPDATE   \n",
       "6929315F  EMISSIONS_INTENSITY_SHOCK  REVENUE_REBALANCE_UPDATE   \n",
       "780A1969                  NO_SHOCKS                MPC_UPDATE   \n",
       "78262511                  NO_SHOCKS                 NO_UPDATE   \n",
       "7958E7BA                  NO_SHOCKS                 NO_UPDATE   \n",
       "993808E9                  NO_SHOCKS                 NO_UPDATE   \n",
       "D368B8D5                  NO_SHOCKS                 NO_UPDATE   \n",
       "F8814267  EMISSIONS_INTENSITY_SHOCK                 NO_UPDATE   \n",
       "\n",
       "                                                description  \\\n",
       "1AE01292             carbon tax - emissions intensity shock   \n",
       "25509009       Attempt to re-balance revenue in each period   \n",
       "5B6BDE7D  Use MPC to achieve revenue target at end of ho...   \n",
       "6929315F       Attempt to re-balance revenue in each period   \n",
       "780A1969  Use MPC to achieve revenue target at end of ho...   \n",
       "78262511                             business as usual case   \n",
       "7958E7BA                             carbon tax - no shocks   \n",
       "993808E9                             business as usual case   \n",
       "D368B8D5                             carbon tax - no shocks   \n",
       "F8814267             carbon tax - emissions intensity shock   \n",
       "\n",
       "                     forecast_generator_emissions_intensity  \\\n",
       "1AE01292                                                 {}   \n",
       "25509009  {1: {1: {'DRYCGT1': 1.35599, 'BW01': 0.9674, '...   \n",
       "5B6BDE7D  {1: {1: {'DRYCGT1': 1.35599, 'BW01': 0.9674, '...   \n",
       "6929315F  {1: {1: {'DRYCGT1': 1.35599, 'BW01': 0.9674, '...   \n",
       "780A1969  {1: {1: {'DRYCGT1': 1.35599, 'BW01': 0.9674, '...   \n",
       "78262511                                                 {}   \n",
       "7958E7BA                                                 {}   \n",
       "993808E9                                                 {}   \n",
       "D368B8D5                                                 {}   \n",
       "F8814267                                                 {}   \n",
       "\n",
       "                                  forecast_generator_energy  \\\n",
       "1AE01292                                                 {}   \n",
       "25509009  {1: {1: {'DRYCGT1': 0.0, 'BW01': 110880.0, 'MP...   \n",
       "5B6BDE7D  {1: {1: {'DRYCGT1': 0.0, 'BW01': 110880.0, 'MP...   \n",
       "6929315F  {1: {1: {'DRYCGT1': 0.0, 'BW01': 110880.0, 'MP...   \n",
       "780A1969  {1: {1: {'DRYCGT1': 0.0, 'BW01': 110880.0, 'MP...   \n",
       "78262511                                                 {}   \n",
       "7958E7BA                                                 {}   \n",
       "993808E9                                                 {}   \n",
       "D368B8D5                                                 {}   \n",
       "F8814267                                                 {}   \n",
       "\n",
       "          forecast_interval_mpc  week_of_shock  default_baseline  \\\n",
       "1AE01292                    NaN            3.0                 0   \n",
       "25509009                    NaN            NaN                 0   \n",
       "5B6BDE7D                    6.0            3.0                 0   \n",
       "6929315F                    NaN            3.0                 0   \n",
       "780A1969                    6.0            NaN                 0   \n",
       "78262511                    NaN            NaN                 0   \n",
       "7958E7BA                    NaN            NaN                 0   \n",
       "993808E9                    NaN            NaN                 0   \n",
       "D368B8D5                    NaN            NaN                 0   \n",
       "F8814267                    NaN            3.0                 0   \n",
       "\n",
       "          initial_permit_price  initial_rolling_scheme_revenue  \\\n",
       "1AE01292                    40                               0   \n",
       "25509009                    40                               0   \n",
       "5B6BDE7D                    40                               0   \n",
       "6929315F                    40                               0   \n",
       "780A1969                    40                               0   \n",
       "78262511                     0                               0   \n",
       "7958E7BA                    40                               0   \n",
       "993808E9                     0                               0   \n",
       "D368B8D5                    40                               0   \n",
       "F8814267                    40                               0   \n",
       "\n",
       "                                      target_scheme_revenue  seed  \\\n",
       "1AE01292                                                 {}    10   \n",
       "25509009  {1: 100000.0, 2: 200000.0, 3: 300000.0, 4: 400...    10   \n",
       "5B6BDE7D  {1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: ...    10   \n",
       "6929315F  {1: 0, 2: 0, 3: 0, 4: 0, 5: 2500000.0, 6: 3000...    10   \n",
       "780A1969             {1: 0, 2: 0, 3: 0, 4: 0, 5: 1000000.0}    10   \n",
       "78262511                                                 {}    10   \n",
       "7958E7BA                                                 {}    10   \n",
       "993808E9                                                 {}    10   \n",
       "D368B8D5                                                 {}    10   \n",
       "F8814267                                                 {}    10   \n",
       "\n",
       "          model_horizon intermittent_generators_regulated  \\\n",
       "1AE01292             10                               NaN   \n",
       "25509009             10                               NaN   \n",
       "5B6BDE7D             10                               NaN   \n",
       "6929315F             10                               NaN   \n",
       "780A1969             10                               NaN   \n",
       "78262511             10                                {}   \n",
       "7958E7BA             10                                {}   \n",
       "993808E9             10                               NaN   \n",
       "D368B8D5             10                               NaN   \n",
       "F8814267             10                                {}   \n",
       "\n",
       "         forecast_intermittent_generator_energy  \n",
       "1AE01292                                    NaN  \n",
       "25509009                                    NaN  \n",
       "5B6BDE7D                                    NaN  \n",
       "6929315F                                    NaN  \n",
       "780A1969                                    NaN  \n",
       "78262511                                     {}  \n",
       "7958E7BA                                     {}  \n",
       "993808E9                                    NaN  \n",
       "D368B8D5                                    NaN  \n",
       "F8814267                                     {}  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_run_summaries(results_dir):\n",
    "    \"\"\"Collate information summarising the parameters used in each run\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    results_dir : str\n",
    "        Directory containing model output\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    run_summaries : dict\n",
    "        Dictionary summarising model parameterisations    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Find all results summary files\n",
    "    run_summary_files = [i for i in os.listdir(results_dir) if 'run_summary' in i]\n",
    "\n",
    "    # Container for dictionaries summarising model runs\n",
    "    run_summaries = dict()\n",
    "\n",
    "    # Open each run summary file and compile in a single dictionary\n",
    "    for i in run_summary_files:\n",
    "        with open(os.path.join(results_dir, i), 'rb') as f:\n",
    "            # Load run summary from file\n",
    "            run_summary = pickle.load(f)\n",
    "            \n",
    "            # Append to dictionary collating all run summaries\n",
    "            run_summaries = {**run_summaries, **run_summary}\n",
    "            \n",
    "    return run_summaries\n",
    "\n",
    "# Directory containing model output\n",
    "results_dir = os.path.join(os.path.curdir, 'output')\n",
    "\n",
    "# Summary of parameters used for each run\n",
    "run_summaries = pd.DataFrame.from_dict(get_all_run_summaries(results_dir), orient='index')\n",
    "run_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Forecast signals\n",
    "# ---------------\n",
    "# 1. For the carbon tax case (no emissions intensity shock)\n",
    "# - re-balance signal\n",
    "# - MPC signal\n",
    "\n",
    "# 2. For the carbon tax + emissions intensity shock case\n",
    "# - re-balance signal\n",
    "# - MPC signal\n",
    "\n",
    "# Construct perfect signals first (test to see if revenue re-balancing is correct)\n",
    "# Perturb perfect forecast signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perfect_forecasts(run_id, forecast_intervals):\n",
    "    \"\"\"Get perfect forecast for energy and emissions intensity based on previous model results\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    run_id : str\n",
    "        ID for run already completed that will result in same emissions / energy output profiles\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    forecast_generator_energy : dict\n",
    "        Perfect forecast for generator energy output in each week\n",
    "    \n",
    "    forecast_generator_emissions_intensity : dict\n",
    "        Perfect forecast for generator emissions intensities in each week   \n",
    "    \"\"\"\n",
    "    \n",
    "    # Load run summary for given run_id\n",
    "    with open(f'output/{run_id}_run_summary.pickle', 'rb') as f:\n",
    "        run_summary = pickle.load(f)\n",
    "\n",
    "    # Max number of intervals for which forecast can be constructed (based on simulation that\n",
    "    # produces same energy and emissions profile)\n",
    "    total_intervals = run_summary[f'{run_id}']['model_horizon']\n",
    "    \n",
    "    # Load weekly results for given run_id\n",
    "    with open(f'output/{run_id}_week_metrics.pickle', 'rb') as f:\n",
    "        week_metrics = pickle.load(f)\n",
    "\n",
    "    # Forecast energy\n",
    "    forecast_generator_energy = {i: {j+1: week_metrics['regulated_generator_energy_MWh'][i+j] for j in range(0, forecast_intervals)} for i in range(1, total_intervals+1-forecast_intervals+1)}\n",
    "\n",
    "    # Forecast generator emissions intensities\n",
    "    forecast_generator_emissions_intensity = {i: {j+1: week_metrics['regulated_generator_emissions_intensities'][i+j] for j in range(0, forecast_intervals)} for i in range(1, total_intervals+1-forecast_intervals+1)}\n",
    "\n",
    "    return forecast_generator_energy, forecast_generator_emissions_intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfect forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model REVENUE_REBALANCE_UPDATE with run option NO_SHOCKS\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-29d9476f2015>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m                    \u001b[0mtarget_scheme_revenue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_scheme_revenue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                    \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                    model_horizon=model_horizon)\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# Check that updating rule has worked correctly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-c3ebb7012dce>\u001b[0m in \u001b[0;36mrun_model\u001b[1;34m(data_dir, scenarios_dir, shock_option, update_mode, description, intermittent_generators_regulated, forecast_generator_emissions_intensity, forecast_generator_energy, forecast_intermittent_generator_energy, forecast_interval_mpc, week_of_shock, default_baseline, initial_permit_price, initial_rolling_scheme_revenue, target_scheme_revenue, seed, model_horizon)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[1;31m# Forecast energy from intermittent reneweable generators (may be under scheme's remit)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m             \u001b[0mforecast_intermittent_generator_total_energy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforecast_intermittent_generator_energy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mweek_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;31m# Forecast regulated generator energy in next period. Value may change depending on whether or not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "# Revenue re-balance - no shocks\n",
    "# ------------------------------\n",
    "# run_id corresponding to previously simulated scenario that doesn't consider updates\n",
    "forecast_run_id = 'D368B8D5'\n",
    "\n",
    "# Forecasts to be used in model\n",
    "forecast_generator_energy, forecast_generator_emissions_intensity = get_perfect_forecasts(run_id=forecast_run_id, forecast_intervals=1)\n",
    "\n",
    "# Target scheme revenue - revenue neutral policy\n",
    "target_scheme_revenue = {i: 100e3 * i for i in range(1, run_summaries.loc[forecast_run_id, 'model_horizon']+1)}\n",
    "\n",
    "# Run model with revenue rebalancing rule\n",
    "run_id = run_model(data_dir=data_dir,\n",
    "                   scenarios_dir=scenarios_dir,\n",
    "                   shock_option='NO_SHOCKS',\n",
    "                   update_mode='REVENUE_REBALANCE_UPDATE',\n",
    "                   description='Attempt to re-balance revenue in each period',\n",
    "                   forecast_generator_emissions_intensity=forecast_generator_emissions_intensity,\n",
    "                   forecast_generator_energy=forecast_generator_energy,\n",
    "                   forecast_interval_mpc=None,\n",
    "                   week_of_shock=None,\n",
    "                   default_baseline=0,\n",
    "                   initial_permit_price=40,\n",
    "                   initial_rolling_scheme_revenue=0,\n",
    "                   target_scheme_revenue=target_scheme_revenue,\n",
    "                   seed=10,\n",
    "                   model_horizon=model_horizon)\n",
    "\n",
    "# Check that updating rule has worked correctly\n",
    "with open(f'output/{run_id}_week_metrics.pickle', 'rb') as f:\n",
    "    week_metrics = pickle.load(f)\n",
    "pd.DataFrame(week_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revenue re-balance - emissions intensity shock\n",
    "# ----------------------------------------------\n",
    "# run_id corresponding to previously simulated scenario that doesn't consider updates\n",
    "forecast_run_id = '1AE01292'\n",
    "\n",
    "# Forecasts to be used in model\n",
    "forecast_generator_energy, forecast_generator_emissions_intensity = get_perfect_forecasts(run_id=forecast_run_id, forecast_intervals=1)\n",
    "\n",
    "# Target scheme revenue - revenue neutral policy\n",
    "target_scheme_revenue = {i: 0 for i in range(1, run_summaries.loc[forecast_run_id, 'model_horizon']+1)}\n",
    "target_scheme_revenue = {i: 0 if i < 5 else 500e3*i for i in range(1, run_summaries.loc[forecast_run_id, 'model_horizon']+1)}\n",
    "\n",
    "# Run model with revenue rebalancing rule\n",
    "run_id = run_model(data_dir=data_dir,\n",
    "                   scenarios_dir=scenarios_dir,\n",
    "                   shock_option='EMISSIONS_INTENSITY_SHOCK',\n",
    "                   update_mode='REVENUE_REBALANCE_UPDATE',\n",
    "                   description='Attempt to re-balance revenue in each period',\n",
    "                   forecast_generator_emissions_intensity=forecast_generator_emissions_intensity,\n",
    "                   forecast_generator_energy=forecast_generator_energy,\n",
    "                   forecast_interval_mpc=None,\n",
    "                   week_of_shock=week_of_shock,\n",
    "                   default_baseline=0,\n",
    "                   initial_permit_price=40,\n",
    "                   initial_rolling_scheme_revenue=0,\n",
    "                   target_scheme_revenue=target_scheme_revenue,\n",
    "                   seed=10,\n",
    "                   model_horizon=model_horizon)\n",
    "\n",
    "# Check that updating rule has worked correctly\n",
    "with open(f'output/{run_id}_week_metrics.pickle', 'rb') as f:\n",
    "    week_metrics = pickle.load(f)\n",
    "pd.DataFrame(week_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MPC update - no shocks\n",
    "# ------------------------------\n",
    "# run_id corresponding to previously simulated scenario that doesn't consider updates\n",
    "forecast_run_id = 'D368B8D5'\n",
    "\n",
    "# Number of forecast intervals to be used when implementing MPC controller\n",
    "forecast_intervals = 6\n",
    "\n",
    "# Forecasts to be used in model\n",
    "forecast_generator_energy, forecast_generator_emissions_intensity = get_perfect_forecasts(run_id=forecast_run_id, forecast_intervals=forecast_intervals)\n",
    "\n",
    "# Target scheme revenue - revenue neutral policy - defines revenue to be attained at end of forecast interval\n",
    "target_scheme_revenue = {i: 0 for i in range(1, run_summaries.loc[forecast_run_id, 'model_horizon']+1-forecast_intervals+1)}\n",
    "target_scheme_revenue[run_summaries.loc[forecast_run_id, 'model_horizon']-forecast_intervals+1] = 1e6\n",
    "\n",
    "# Run model with revenue rebalancing rule\n",
    "run_id = run_model(data_dir=data_dir,\n",
    "                   scenarios_dir=scenarios_dir,\n",
    "                   shock_option='NO_SHOCKS',\n",
    "                   update_mode='MPC_UPDATE',\n",
    "                   description='Use MPC to achieve revenue target at end of horizon',\n",
    "                   forecast_generator_emissions_intensity=forecast_generator_emissions_intensity,\n",
    "                   forecast_generator_energy=forecast_generator_energy,\n",
    "                   forecast_interval_mpc=forecast_intervals,\n",
    "                   week_of_shock=None,\n",
    "                   default_baseline=0,\n",
    "                   initial_permit_price=40,\n",
    "                   initial_rolling_scheme_revenue=0,\n",
    "                   target_scheme_revenue=target_scheme_revenue,\n",
    "                   seed=10,\n",
    "                   model_horizon=model_horizon)\n",
    "\n",
    "# Check that updating rule has worked correctly\n",
    "with open(f'output/{run_id}_week_metrics.pickle', 'rb') as f:\n",
    "    week_metrics = pickle.load(f)\n",
    "pd.DataFrame(week_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPC update - emissions intensity shock\n",
    "# --------------------------------------\n",
    "# run_id corresponding to previously simulated scenario that doesn't consider updates\n",
    "forecast_run_id = '1AE01292'\n",
    "\n",
    "# Number of forecast intervals to be used when implementing MPC controller\n",
    "forecast_intervals = 6\n",
    "\n",
    "# Forecasts to be used in model\n",
    "forecast_generator_energy, forecast_generator_emissions_intensity = get_perfect_forecasts(run_id=forecast_run_id, forecast_intervals=forecast_intervals)\n",
    "\n",
    "# Target scheme revenue - revenue neutral policy\n",
    "target_scheme_revenue = {i: 0 for i in range(1, run_summaries.loc[forecast_run_id, 'model_horizon']+1)}\n",
    "\n",
    "# Run model with revenue rebalancing rule\n",
    "run_id = run_model(data_dir=data_dir,\n",
    "                   scenarios_dir=scenarios_dir,\n",
    "                   shock_option='EMISSIONS_INTENSITY_SHOCK',\n",
    "                   update_mode='MPC_UPDATE',\n",
    "                   description='Use MPC to achieve revenue target at end of horizon',\n",
    "                   forecast_generator_emissions_intensity=forecast_generator_emissions_intensity,\n",
    "                   forecast_generator_energy=forecast_generator_energy,\n",
    "                   forecast_interval_mpc=forecast_intervals,\n",
    "                   week_of_shock=week_of_shock,\n",
    "                   default_baseline=0,\n",
    "                   initial_permit_price=40,\n",
    "                   initial_rolling_scheme_revenue=0,\n",
    "                   target_scheme_revenue=target_scheme_revenue,\n",
    "                   seed=10,\n",
    "                   model_horizon=model_horizon)\n",
    "\n",
    "# Check that updating rule has worked correctly\n",
    "with open(f'output/{run_id}_week_metrics.pickle', 'rb') as f:\n",
    "    week_metrics = pickle.load(f)\n",
    "pd.DataFrame(week_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imperfect forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.clf()\n",
    "pd.DataFrame(week_metrics)['baseline'].plot(drawstyle='steps-post')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opti env",
   "language": "python",
   "name": "opti"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
